import pandas as pd
import hashlib, json, os, requests, importlib.util, subprocess, time
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from supabase import create_client

class UniversalFactory:
    def __init__(self, masters_path="masters"):
        self.masters_path = Path(masters_path)
        self.masters = self._load_masters()
        self.api_key = os.environ.get("SILICON_FLOW_KEY")
        self.api_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.supabase_url = os.environ.get("SUPABASE_URL")
        self.supabase_key = os.environ.get("SUPABASE_KEY")
        self.vault_path = None
        
        self.v3_model = "deepseek-ai/DeepSeek-V3"
        self.free_model = "Qwen/Qwen2.5-7B-Instruct"

    def _load_masters(self):
        masters = {}
        if not self.masters_path.exists(): return masters
        for file_path in self.masters_path.glob("*.py"):
            if file_path.name.startswith("__"): continue
            try:
                name = file_path.stem
                spec = importlib.util.spec_from_file_location(name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                if hasattr(module, 'audit'): masters[name] = module
            except: pass
        return masters

    def fetch_best_signals(self, limit=300):
        """å°è¯•ä» SQL è·å–ï¼Œå¦‚æœè¡¨åä¸å¯¹ä¼šæŠ¥é”™ï¼Œç”±ä¸»å‡½æ•°æ•è·"""
        print(f"ğŸ“¡ å°è¯•è¿æ¥ SQL ç­›é€‰å‰ {limit} æ¡ç²¾å...")
        supabase = create_client(self.supabase_url, self.supabase_key)
        # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œå‡è®¾è¡¨åå« raw_signalsï¼Œå¦‚æœä½ çš„è¡¨å« items æˆ–å…¶ä»–åå­—ï¼Œè¯·ä¿®æ”¹è¿™é‡Œ
        response = supabase.table("raw_signals") \
            .select("*") \
            .order("created_at", desc=True) \
            .limit(limit) \
            .execute()
        return response.data

    def call_ai(self, model, sys, usr):
        if not self.api_key: return "ERROR", "Missing Key"
        payload = {
            "model": model, "messages": [{"role": "system", "content": sys}, {"role": "user", "content": usr}],
            "temperature": 0.7, "max_tokens": 1024
        }
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        try:
            res = requests.post(self.api_url, json=payload, headers=headers, timeout=45).json()
            return "SUCCESS", res['choices'][0]['message']['content']
        except: return "ERROR", "Timeout"

    def git_push_assets(self):
        if not self.vault_path: return
        try:
            cwd = self.vault_path
            subprocess.run(["git", "add", "."], cwd=cwd, check=True)
            status = subprocess.run(["git", "diff", "--cached", "--quiet"], cwd=cwd)
            if status.returncode != 0:
                print("ğŸ“¦ [åˆ†æ‰¹åŒæ­¥] èµ„äº§å…¥åº“ä¸­...")
                subprocess.run(["git", "commit", "-m", f"ğŸ§  Batch Sync: {datetime.now().strftime('%H:%M:%S')}"], cwd=cwd, check=True)
                subprocess.run(["git", "push"], cwd=cwd, check=True)
        except Exception as e: print(f"âš ï¸ GitåŒæ­¥è­¦å‘Š: {e}")

    def audit_process(self, row):
        # å…¼å®¹ä¸åŒæ•°æ®æºçš„å­—æ®µå
        content = str(row.get('full_text') or row.get('eventTitle') or row.get('text') or '')
        if not content: return []

        ref_id = hashlib.sha256(content.encode()).hexdigest()
        
        # 1. å…è´¹æ‰“åˆ† (Scout)
        scout_sys = "ä½ æ˜¯ä¸€ä¸ªé«˜ä»·å€¼ä¿¡æ¯ç­›é€‰å™¨ã€‚ç»™ä»¥ä¸‹å†…å®¹æ‰“åˆ†(0-100)ã€‚åªå›ç­”æ•°å­—ã€‚"
        _, score_reply = self.call_ai(self.free_model, scout_sys, content[:500])
        
        try: score = int(''.join(filter(str.isdigit, score_reply)))
        except: score = 50

        results = []
        title = content[:50]
        
        # ç²¾åï¼šV3 å…¨é‡
        if score > 80:
            def ask_v3(s, u):
                st, r = self.call_ai(self.v3_model, s, u)
                if st == "SUCCESS" and "### Output" in r:
                    return r.split("### Output")[0].replace("### Thought","").strip(), r.split("### Output")[1].strip()
                return "ç»¼åˆç ”åˆ¤", r
            
            for name, mod in self.masters.items():
                try:
                    t, o = mod.audit(row, ask_v3)
                    if t and o: results.append(json.dumps({"ref_id":ref_id, "master":name, "instruction":f"ç ”åˆ¤: {title}", "thought":t, "output":o}, ensure_ascii=False))
                except: continue
        
        # æ™®é€šï¼šå…è´¹å¿«è¯„
        elif score > 50:
            st, r = self.call_ai(self.free_model, "è¯·ç”¨ä¸€å¥è¯æå–å…³é”®ä»·å€¼", content[:500])
            if st == "SUCCESS":
                results.append(json.dumps({"ref_id":ref_id, "master":"system", "instruction":f"å¿«è¯„: {title}", "thought":"å¿«é€Ÿæ‰«æ", "output":r}, ensure_ascii=False))

        return results

    def process_and_ship(self, input_raw, vault_path):
        self.vault_path = Path(vault_path)
        signals = []
        
        # ğŸ›¡ï¸ã€åŒä¿é™©é€»è¾‘ã€‘å…ˆè¯• SQLï¼Œä¸è¡Œå°±è¯»æ–‡ä»¶
        try:
            signals = self.fetch_best_signals(limit=300)
            print(f"âœ… SQL è¿æ¥æˆåŠŸï¼Œè·å–åˆ° {len(signals)} æ¡æ•°æ®ã€‚")
        except Exception as e:
            print(f"âš ï¸ SQL è¡¨åé”™è¯¯æˆ–è¿æ¥å¤±è´¥: {e}")
            print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢è‡³æœ¬åœ°æ–‡ä»¶æ¨¡å¼ (è¯»å– {input_raw})...")
            try:
                # é™çº§è¯»å–æœ¬åœ° Parquet
                df = pd.read_parquet(input_raw)
                # æ¨¡æ‹Ÿ limit=300
                signals = df.head(300).to_dict('records')
                print(f"âœ… æœ¬åœ°æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå¤„ç†å‰ {len(signals)} æ¡ã€‚")
            except Exception as file_e:
                print(f"âŒ ä¸¥é‡é”™è¯¯: æœ¬åœ°æ–‡ä»¶ä¹Ÿæ— æ³•è¯»å–: {file_e}")
                return

        day_str = datetime.now().strftime('%Y%m%d')
        output_file = self.vault_path / "instructions" / f"teachings_{day_str}.jsonl"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        batch_size = 50
        print(f"ğŸš€ å·¥å‚å¼€å·¥ï¼å½“å‰æ¨¡å¼: {'SQLç²¾é€‰' if 'raw_signals' in str(signals) else 'æœ¬åœ°æ–‡ä»¶'}")

        for i in range(0, len(signals), batch_size):
            batch_rows = signals[i : i + batch_size]
            
            with ThreadPoolExecutor(max_workers=10) as executor:
                batch_results = list(executor.map(self.audit_process, batch_rows))
            
            batch_added = 0
            with open(output_file, 'a', encoding='utf-8') as f:
                for res_list in batch_results:
                    if res_list:
                        f.write('\n'.join(res_list) + '\n')
                        batch_added += 1
            
            print(f"âœ¨ è¿›åº¦: {i+len(batch_rows)}/{len(signals)}ã€‚æœ¬æ‰¹æ¬¡äº§å‡º {batch_added} æ¡ã€‚")
            self.git_push_assets()

        print("ğŸ ä»»åŠ¡å®Œæˆã€‚")
