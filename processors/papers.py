import json
from datetime import datetime, timedelta

# å¯¹åº” Supabase é‡Œçš„è¡¨å
TABLE_NAME = "papers_logs"

def fmt_k(num):
    if not num: return "0"
    try: n = float(num)
    except: return "0"
    if n >= 1_000: return f"{n/1_000:.1f}K"
    return str(int(n))

# === 1. æ•°æ®æ¸…æ´—é€»è¾‘ (ä¿æŒä¸å˜) ===
def process(raw_data, path):
    # å…¼å®¹å¤„ç†ï¼šæœ‰äº› JSON æ˜¯ dict (å« meta)ï¼Œæœ‰äº›å¯èƒ½æ˜¯ list
    data = raw_data if isinstance(raw_data, dict) else {}
    items = data.get("items", [])
    meta = data.get("meta", {})
    
    # è·å–æ‰«ææ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨å½“å‰æ—¶é—´
    scanned_at = meta.get("scanned_at_bj")
    if not scanned_at:
        scanned_at = datetime.now().isoformat()
        
    refined_results = []
    for i in items:
        # æå– metricsï¼Œé˜²æ­¢ key ä¸å­˜åœ¨æŠ¥é”™
        metrics = i.get("metrics", {})
        
        row = {
            "bj_time": scanned_at,
            "title": i.get("title"),
            "journal": i.get("journal"),
            # åŒºåˆ† â˜¢ï¸ NUCLEAR å’Œ âš¡ EARLY_SIGNAL
            "signal_type": i.get("type", "General"), 
            "citations": int(metrics.get("citations", 0)),
            "impact_factor": float(metrics.get("impact_factor", 0.0)),
            # æ•°ç»„è½¬ JSON å­—ç¬¦ä¸²
            "strategies": i.get("strategies", []), 
            "url": i.get("url"),
            "reason": i.get("reason"),
            "raw_json": i
        }
        refined_results.append(row)
    return refined_results

# === 2. æˆ˜æŠ¥ç”Ÿæˆé€»è¾‘ (ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼š3+10 ç­›é€‰æ³•) ===
def get_hot_items(supabase, table_name):
    # åªçœ‹æœ€è¿‘ 24 å°æ—¶çš„æ•°æ®
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_papers = res.data if res.data else []
    except Exception as e:
        print(f"Papers DB Error: {e}")
        return {}
    
    if not all_papers: return {}

    # A. å»é‡é€»è¾‘
    unique_map = {}
    for p in all_papers:
        title = p.get("title")
        if not title: continue
        # å¦‚æœé‡å¤ï¼Œä¿ç•™å¼•ç”¨æ•°æ›´é«˜çš„ç‰ˆæœ¬
        if title not in unique_map or p.get("citations", 0) > unique_map[title].get("citations", 0):
            unique_map[title] = p
    
    papers = list(unique_map.values())
    
    # ğŸ”¥ B. åˆ†ç»„ç­›é€‰ç­–ç•¥ (3 Nuclear + 10 Others)
    
    # 1. æå– Nuclear (æ ¸çˆ†çº§ä¿¡å·)
    nuclear_candidates = [p for p in papers if "NUCLEAR" in p.get("signal_type", "")]
    nuclear_candidates.sort(key=lambda x: x.get("citations", 0), reverse=True)
    # é™åˆ¶æœ€å¤šæ˜¾ç¤º 3 ä¸ªï¼Œå®ç¼ºæ¯‹æ»¥
    final_nuclear = nuclear_candidates[:3]

    # 2. æå– Others (å¸¸è§„/æ—©æœŸä¿¡å·)
    other_candidates = [p for p in papers if "NUCLEAR" not in p.get("signal_type", "")]
    # æŒ‰å¼•ç”¨æ•°é™åºæ’åº
    other_candidates.sort(key=lambda x: x.get("citations", 0), reverse=True)
    
    # ğŸ’¡ è´¨é‡è¿‡æ»¤å™¨ï¼šå¦‚æœæ˜¯ 0 å¼•ç”¨ï¼Œä¸”æ²¡æœ‰ "EARLY" æ ‡ç­¾ï¼Œå¯èƒ½æ˜¯å‡‘æ•°çš„ï¼Œå»ºè®®è¿‡æ»¤
    # è¿™é‡Œæˆ‘ä»¬åªå–å‰ 10 ä¸ª
    final_others = other_candidates[:10]

    # 3. åˆå¹¶åˆ—è¡¨ï¼šæ ¸çˆ†çº§æ°¸è¿œç½®é¡¶
    final_display_list = final_nuclear + final_others

    if not final_display_list: return {}

    # C. æ„å»º Markdown è¡¨æ ¼
    header = "| ä¿¡å· | æ ‡é¢˜ | å¼•ç”¨ | æ ‡ç­¾ (å…³é”®è¯) | ğŸ”— |\n| :--- | :--- | :--- | :--- | :--- |"
    rows = []
    
    for p in final_display_list:
        s_type = p.get("signal_type","")
        # å›¾æ ‡ç¾åŒ–
        if "NUCLEAR" in s_type:
            icon = "â˜¢ï¸ **NUCLEAR**"
        elif "EARLY" in s_type:
            icon = "âš¡ Early"
        else:
            icon = "ğŸ“„ Paper"
            
        title = p.get("title", "")
        if len(title) > 65: title = title[:65] + "..."
            
        cite = fmt_k(p.get("citations", 0))
        
        # å¤„ç†æ ‡ç­¾æ˜¾ç¤º
        tags = p.get("strategies", [])
        if isinstance(tags, str):
            try: tags = json.loads(tags)
            except: tags = []
        
        # æ ‡ç­¾åŠ ç²—æ˜¾ç¤ºï¼Œè§†è§‰æ›´æ¸…æ™°ï¼Œåªå–å‰2ä¸ª
        tag_str = ", ".join([f"**{t}**" for t in tags[:2]])
        
        url = p.get("url", "#")
        
        rows.append(f"| {icon} | {title} | {cite} | {tag_str} | [ğŸ”—]({url}) |")
        
    return {"ğŸ”¬ Science Radar (ç§‘ç ”å‰å“¨)": {"header": header, "rows": rows}}
