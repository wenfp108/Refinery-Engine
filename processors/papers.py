import json
from datetime import datetime, timedelta

# å¯¹åº” Supabase é‡Œçš„è¡¨å
TABLE_NAME = "papers_logs"

def fmt_k(num):
    if not num: return "0"
    try: n = float(num)
    except: return "0"
    if n >= 1_000: return f"{n/1_000:.1f}K"
    return str(int(n))

# === 1. æ•°æ®æ¸…æ´—é€»è¾‘ (ä¿æŒä¸å˜) ===
def process(raw_data, path):
    data = raw_data if isinstance(raw_data, dict) else {}
    items = data.get("items", [])
    meta = data.get("meta", {})
    
    scanned_at = meta.get("scanned_at_bj")
    if not scanned_at:
        scanned_at = datetime.now().isoformat()
        
    refined_results = []
    for i in items:
        metrics = i.get("metrics", {})
        row = {
            "bj_time": scanned_at,
            "title": i.get("title"),
            "journal": i.get("journal"),
            # åŒºåˆ† NUCLEAR (æ ¸çˆ†) å’Œ EARLY (å‰æ²¿)
            "signal_type": i.get("type", "General"), 
            "citations": int(metrics.get("citations", 0)),
            "impact_factor": float(metrics.get("impact_factor", 0.0)),
            "strategies": i.get("strategies", []), 
            "url": i.get("url"),
            "reason": i.get("reason"),
            "raw_json": i
        }
        refined_results.append(row)
    return refined_results

# === 2. æˆ˜æŠ¥ç”Ÿæˆé€»è¾‘ (ğŸ”¥ ä¿®æ”¹ï¼š3æ ¸çˆ† + 7å‰æ²¿) ===
def get_hot_items(supabase, table_name):
    # è·å–æœ€è¿‘ 24 å°æ—¶æ•°æ®
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_papers = res.data if res.data else []
    except Exception as e:
        print(f"Papers DB Error: {e}")
        return {}
    
    if not all_papers: return {}

    # A. å»é‡ (ä¿ç•™å¼•ç”¨æ›´é«˜çš„ç‰ˆæœ¬)
    unique_map = {}
    for p in all_papers:
        title = p.get("title")
        if not title: continue
        if title not in unique_map or p.get("citations", 0) > unique_map[title].get("citations", 0):
            unique_map[title] = p
    papers = list(unique_map.values())
    
    # ğŸ”¥ B. å’¨è¯¢é¡¾é—®ç­›é€‰æ³• (Consultant's Filter)
    
    # 1. â˜¢ï¸ Nuclear Pool (æ ¸çˆ†æ± ) - åªè¦å‰ 3 ä¸ª
    # è¿™äº›æ˜¯å¿…é¡»çŸ¥é“çš„å¤§äº‹ä»¶
    nuclear_pool = [p for p in papers if "NUCLEAR" in p.get("signal_type", "")]
    nuclear_pool.sort(key=lambda x: x.get("citations", 0), reverse=True)
    final_nuclear = nuclear_pool[:3]

    # 2. âš¡ Frontier Pool (å‰æ²¿æ± ) - åªè¦å‰ 7 ä¸ª
    # æ ¸å¿ƒé€»è¾‘ï¼šæ‰¾ "EARLY" ä¿¡å·ï¼Œæˆ–è€…æ˜¯å¸¦æœ‰ç‰¹å®šç­–ç•¥æ ‡ç­¾çš„è®ºæ–‡
    # å¦‚æœå¼•ç”¨æ•°ä¸é«˜ä½†è¢«æ ‡è®°ä¸º EARLYï¼Œè¯´æ˜å®ƒæ˜¯æ½œåŠ›è‚¡
    def frontier_score(p):
        score = 0
        # åªè¦æ˜¯ Early å°±ç»™é«˜åˆ†ï¼Œå‹å€’æ™®é€šçš„é«˜å¼•ç”¨è®ºæ–‡
        if "EARLY" in p.get("signal_type", ""): score += 10000
        # æœ‰ç­–ç•¥æ ‡ç­¾ï¼ˆå¦‚ BIO_REVOLUTIONï¼‰åŠ åˆ†
        if p.get("strategies"): score += 5000
        # æœ€åæ‰çœ‹å¼•ç”¨æ•°ï¼Œä½œä¸ºè¾…åŠ©
        score += p.get("citations", 0)
        return score

    # æ’é™¤æ‰å·²ç»é€‰å…¥ Nuclear çš„
    nuclear_ids = {p['title'] for p in final_nuclear}
    remaining_papers = [p for p in papers if p['title'] not in nuclear_ids]
    
    remaining_papers.sort(key=frontier_score, reverse=True)
    final_frontier = remaining_papers[:7]

    # åˆå¹¶åˆ—è¡¨
    final_display_list = final_nuclear + final_frontier

    if not final_display_list: return {}

    # C. æ„å»º Markdown (å¢åŠ  "æ½œåŠ›" è§†è§‰æç¤º)
    header = "| ä¿¡å· | æ ‡é¢˜ | å¼•ç”¨ | é¢†åŸŸ (æ½œåŠ›æ–¹å‘) | ğŸ”— |\n| :--- | :--- | :--- | :--- | :--- |"
    rows = []
    
    for p in final_display_list:
        s_type = p.get("signal_type","")
        
        # å›¾æ ‡é€»è¾‘
        if "NUCLEAR" in s_type:
            icon = "â˜¢ï¸ **NUCLEAR**"
        elif "EARLY" in s_type:
            icon = "âš¡ **Early**"  # å¼ºè°ƒ Early
        else:
            icon = "ğŸ“„ Paper"
            
        title = p.get("title", "")
        # ç¨å¾®ç¼©çŸ­æ ‡é¢˜ï¼Œè®©è¡¨æ ¼æ›´æ•´æ´
        if len(title) > 60: title = title[:60] + "..."
            
        cite = fmt_k(p.get("citations", 0))
        
        # æ ‡ç­¾å¤„ç†ï¼šåªæ˜¾ç¤ºæœ€æœ‰ä»·å€¼çš„ 1-2 ä¸ªæ ‡ç­¾
        tags = p.get("strategies", [])
        if isinstance(tags, str):
            try: tags = json.loads(tags)
            except: tags = []
        
        # è§†è§‰ä¼˜åŒ–ï¼šç”¨ä»£ç å—é«˜äº®æ ‡ç­¾ï¼Œä¸€çœ¼çœ‹åˆ° "BIO", "AI" ç­‰å…³é”®è¯
        if tags:
            tag_str = " ".join([f"`{t}`" for t in tags[:2]])
        else:
            tag_str = "-"
        
        url = p.get("url", "#")
        
        rows.append(f"| {icon} | {title} | {cite} | {tag_str} | [ğŸ”—]({url}) |")
        
    return {"ğŸ”¬ Science Radar (ç§‘ç ”å‰å“¨)": {"header": header, "rows": rows}}
