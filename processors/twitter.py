import json
import math
from datetime import datetime, timedelta

TABLE_NAME = "twitter_logs"
TARGET_TOTAL_QUOTA = 30  # ğŸŒŸ æœ€ç»ˆåªé€‰å‡ºå…¨ç½‘æœ€å¥½çš„ 30 æ¡

# === ğŸ›‘ 1. æ”¿æ²»/åƒåœ¾å™ªéŸ³è¯ (æ ¸æ‰“å‡») ===
# åªè¦å‡ºç°è¿™äº›è¯ï¼Œåˆ†æ•°ç›´æ¥æ‰“ 1 æŠ˜ï¼ˆé™¤éæœ‰è±å…æƒï¼‰
NOISE_KEYWORDS = [
    "woke", "maga", "democrat", "republican", "leftist", "right wing", "liberal", "conservative",
    "fascist", "communist", "socialist", "pronouns", "dei", "border crisis", "illegal",
    "trump", "biden", "harris", "vance", "pelosi", "schumer", "election", "ballot",
    "scandal", "epstein", "pedophile", "traitor", "shame", "disgrace", "culture war",
    "nazi", "hitler", "antisemitism", "zionist", "genocide"
]

# === ğŸ”° 2. å®è§‚è±å…è¯ (å…æ­»é‡‘ç‰Œ) ===
# æ”¿æ²»è´´é‡Œå¦‚æœæœ‰è¿™äº›è¯ï¼Œè¯´æ˜åœ¨èŠæ­£äº‹ï¼ˆç«‹æ³•/å®è§‚/ç›‘ç®¡ï¼‰ï¼Œä¸é™æƒ
MACRO_IMMUNITY = [
    "fed", "federal reserve", "powell", "fomc", "rate", "interest", "cut", "hike",
    "tariff", "trade war", "sanction", "export", "import", "duty",
    "china", "taiwan", "russia", "ukraine", "israel", "iran", "war", "military",
    "stimulus", "debt", "deficit", "budget", "tax", "treasury", "bond", "yield",
    "bitcoin", "btc", "crypto", "ban", "regulation", "sec", "gensler", "etf",
    "executive order", "veto", "sign", "bill", "act", "law", "legislation",
    "nominate", "nominee", "appoint", "confirm", "supreme court", "ruling"
]

# === ğŸ§  3. ç²¾å‡†è¯é¢˜è¯åº“ (æƒé‡ç«ä»·æ¨¡å¼) ===
# è¯è¶Šé•¿ã€è¶Šä¸“ä¸šï¼Œæƒé‡è¶Šé«˜ï¼Œé˜²æ­¢è¯¯åˆ¤
TOPIC_RULES = {
    "Crypto": [
        "bitcoin", "btc", "ethereum", "eth", "solana", "defi", "nft", "stablecoin", "usdc", "usdt",
        "etf flow", "blackrock", "layer2", "zk-rollup", "airdrop", "staking", "restaking", "memecoin",
        "binance", "coinbase", "satoshi", "vitalik", "on-chain analysis", "wallet", "altcoin"
    ],
    "AI/Tech": [
        "llm", "transformer", "genai", "generative ai", "inference", "training run", "pre-training",
        "gpt-5", "gpt-4", "claude", "gemini", "llama", "deepseek", "mistral", "anthropic", "openai",
        "nvidia", "nvda", "h100", "blackwell", "cuda", "gpu", "tpu", "asic", "compute",
        "tsmc", "asml", "semiconductor", "chip", "wafer", "moore's law",
        "spacex", "starship", "falcon", "tesla", "tsla", "fsd", "optimus", "robot",
        "python", "rust", "github", "huggingface", "arxiv", "open source"
    ],
    "Science": [
        "nature journal", "science magazine", "arxiv", "peer review", "preprint",
        "nasa", "esa", "jwst", "supernova", "exoplanet", "quantum", "entanglement",
        "superconductor", "lk-99", "fusion energy", "iter", "plasma",
        "crispr", "mrna", "protein", "enzyme", "cancer research", "alzheimer", "longevity"
    ],
    "Macro": [
        "sp500", "nasdaq", "bond yield", "treasury", "curve inversion",
        "gold", "xau", "silver", "crude oil", "brent", "natural gas",
        "earnings call", "revenue", "guidance", "profit margin", "buyback", "dividend",
        "fomc", "fed funds", "powell", "cpi", "ppi", "pce", "inflation", "deflation", "stagflation",
        "gdp", "recession", "soft landing", "non-farm", "unemployment", "jobless", "payroll",
        "balance sheet", "quantitative tightening", "liquidity injection"
    ],
    "Geo": [
        "ukraine", "russia", "putin", "zelensky", "donbas", "kursk",
        "israel", "gaza", "hamas", "hezbollah", "iran", "tehran", "red sea", "houthi",
        "china", "xi jinping", "taiwan", "south china sea", "pla", "semiconductor sanction",
        "nato", "pentagon", "dod", "nuclear", "icbm", "drone warfare"
    ]
}

# === ğŸ›¡ï¸ 4. VIP ç™½åå• (åŸºç¡€åˆ†åŠ æˆ) ===
VIP_AUTHORS = [
    "Karpathy", "Yann LeCun", "Vitalik", "Paul Graham", "Naval", 
    "Eric Topol", "Huberman", "Lex Fridman", "Sam Altman", "Kobeissi Letter",
    "Michael Saylor", "Balaji"
]

def fmt_k(num):
    if not num: return "0"
    try: n = float(num)
    except: return "0"
    if n >= 1_000_000: return f"{n/1_000_000:.1f}M"
    if n >= 1_000: return f"{n/1_000:.1f}K"
    return str(int(n))

def to_iso_bj(date_str):
    try:
        utc_dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S +0000 %Y')
        return (utc_dt + timedelta(hours=8)).isoformat()
    except: return datetime.now().isoformat()

def process(raw_data, path):
    items = raw_data if isinstance(raw_data, list) else [raw_data]
    refined_results = []
    for i in items:
        # ğŸ—‘ï¸ åƒåœ¾è¿‡æ»¤ï¼šæ€æ‰ "Yes..." è¿™ç§æ°´è´´
        text = i.get('fullText', '')
        # å¦‚æœæ­£æ–‡å¤ªçŸ­(<10å­—)ä¸”ä¸åŒ…å«é“¾æ¥ï¼Œç›´æ¥ä¸¢å¼ƒ
        if len(text) < 10 and 'http' not in text:
            continue

        user = i.get('user', {})
        metrics = i.get('metrics', {})
        row = {
            "bj_time": to_iso_bj(i.get('createdAt')),
            "user_name": user.get('name'),
            "screen_name": user.get('screenName'),
            "followers_count": user.get('followersCount'),
            "full_text": text,
            "url": i.get('tweetUrl'), 
            "tags": i.get('tags', []),
            "likes": metrics.get('likes', 0),
            "retweets": metrics.get('retweets', 0),
            "bookmarks": metrics.get('bookmarks', 0),
            "raw_json": i 
        }
        refined_results.append(row)
    return refined_results

# ğŸ”¥ æ ¸å¿ƒï¼šä¸Šå¸æƒé‡ç®—æ³• 3.0 ğŸ”¥
def calculate_score_and_tag(item):
    text = (item.get('full_text') or "").lower()
    user = (item.get('user_name') or "")
    
    # 1. åŸºç¡€çƒ­åº¦ (ä¹¦ç­¾ x10, è½¬æ¨ x5, ç‚¹èµ x1)
    # ä¹¦ç­¾æƒé‡æœ€é«˜ï¼Œå› ä¸ºå®ƒä»£è¡¨æ·±åº¦é˜…è¯»å’Œæ”¶è—ä»·å€¼
    metrics = item.get('raw_json', {}).get('metrics', {})
    base_score = (metrics.get('retweets', 0) * 5) + \
                 (metrics.get('bookmarks', 0) * 10) + \
                 metrics.get('likes', 0)
    
    # 2. è¯é¢˜ç«ä»· (è§£å†³åˆ†ç±»å¹»è§‰)
    detected_topic = "General"
    max_keyword_len = 0 # åŒ¹é…åˆ°çš„å…³é”®è¯è¶Šé•¿ï¼Œç½®ä¿¡åº¦è¶Šé«˜
    
    for topic, keywords in TOPIC_RULES.items():
        for k in keywords:
            # å¿…é¡»åŒ¹é…åˆ°å…³é”®è¯æ‰ç®—
            if k in text:
                # ä¼˜å…ˆçº§é€»è¾‘ï¼šä¿ç•™åŒ¹é…åˆ°çš„æœ€é•¿/æœ€å…·ä½“çš„å…³é”®è¯æ‰€å±çš„è¯é¢˜
                if len(k) > max_keyword_len:
                    detected_topic = topic
                    max_keyword_len = len(k)
    
    # 3. è¯­ä¹‰åŠ æƒ vs é™æƒ
    if detected_topic != "General":
        # ğŸ’ å‘½ä¸­ç¡¬æ ¸æ¿å—ï¼šå¤§å¹…åŠ åˆ†
        base_score += 2000
        base_score *= 1.5
    else:
        # ğŸ“‰ General æƒ©ç½šï¼šæ²¡è¥å…»çš„æ°´è´´ï¼Œåˆ†æ•°æ‰“å¯¹æŠ˜
        # é˜²æ­¢é©¬æ–¯å…‹çš„æ™®é€šæ¨æ–‡åˆ·å±
        base_score *= 0.5 

    # 4. æ”¿æ²»æ’æ¯’ (Nuclear Detox)
    has_noise = False
    for noise in NOISE_KEYWORDS:
        if noise in text:
            has_noise = True
            break
            
    if has_noise:
        # æ£€æŸ¥æ˜¯å¦æœ‰å…æ­»é‡‘ç‰Œ (å®è§‚è±å…)
        is_immune = False
        for safe in MACRO_IMMUNITY:
            if safe in text:
                is_immune = True
                break
        
        if not is_immune:
            base_score *= 0.1 # ğŸ’£ æ— è±å…çš„æ”¿æ²»å™ªéŸ³ï¼Œç›´æ¥æ‰“1æŠ˜
            detected_topic = "Politics" # å¼ºåˆ¶æ ‡è®°
            
    # 5. VIP åŠ æˆ
    for vip in VIP_AUTHORS:
        if vip.lower() in user.lower():
            base_score += 5000
            break
            
    return base_score, detected_topic

def get_hot_items(supabase, table_name):
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_tweets = res.data if res.data else []
    except Exception as e: return {}

    if not all_tweets: return {}

    # 1. URL å»é‡
    unique_map = {}
    for t in all_tweets:
        key = t.get('url') or (t.get('user_name'), t.get('full_text'))
        if key not in unique_map:
            unique_map[key] = t
    tweets = list(unique_map.values())

    # 2. ç®—åˆ† & æ‰“æ ‡
    scored_tweets = []
    for t in tweets:
        score, topic = calculate_score_and_tag(t)
        t['_score'] = score
        t['_topic'] = topic
        scored_tweets.append(t)
        
    # 3. å…¨å±€æ’åº
    scored_tweets.sort(key=lambda x: x['_score'], reverse=True)
    
    # 4. ğŸ›¡ï¸ å¤šæ ·æ€§ç†”æ–­ (Diversity Breaker)
    # é™åˆ¶å•äººéœ¸æ¦œï¼Œæ¯äººæœ€å¤šä¿ç•™å‰ 3 æ¡
    final_list = []
    author_counts = {}
    
    for t in scored_tweets:
        if len(final_list) >= TARGET_TOTAL_QUOTA:
            break
            
        author = t['user_name']
        if author_counts.get(author, 0) >= 3:
            continue
            
        final_list.append(t)
        author_counts[author] = author_counts.get(author, 0) + 1
        
    # 5. ç”Ÿæˆæˆ˜æŠ¥ (å•å¼ å¤§è¡¨)
    header = "| ä¿¡å· | ğŸ·ï¸ æ ‡ç­¾ | çƒ­åº¦ | åšä¸» | æ‘˜è¦ | ğŸ”— |\n| :--- | :--- | :--- | :--- | :--- | :--- |"
    rows = []
    
    for t in final_list:
        score_display = fmt_k(t['_score'])
        
        # æ ‡ç­¾ç¾åŒ–
        topic_raw = t['_topic']
        if topic_raw == "General": 
            topic_str = "General" 
        elif topic_raw == "Politics":
            topic_str = "Politics"
        else: 
            topic_str = f"**{topic_raw}**" # ç¡¬æ ¸æ ‡ç­¾åŠ ç²—æ˜¾ç¤º
        
        # çƒ­åº¦å‚ç›´æ’ç‰ˆ
        heat = f"â¤ï¸ {fmt_k(t.get('likes',0))}<br>ğŸ” {fmt_k(t.get('retweets',0))}" 
        
        user = t['user_name']
        # æ™ºèƒ½æ‘˜è¦ï¼šæˆªå–å‰70å­—ç¬¦ï¼Œå»é™¤æ¢è¡Œ
        text = t['full_text'].replace('\n', ' ')[:70] + "..."
        url = t['url']
        
        rows.append(f"| **{score_display}** | {topic_str} | {heat} | {user} | {text} | [ğŸ”—]({url}) |")

    # è¿”å›ç»™ Refinery çš„ç»Ÿä¸€æ ¼å¼
    return {"ğŸ† å…¨åŸŸç²¾é€‰ (Top 30)": {"header": header, "rows": rows}}
