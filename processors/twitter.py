import json
import math
from datetime import datetime, timedelta

TABLE_NAME = "twitter_logs"
TARGET_TOTAL_QUOTA = 30  # ä¸¥æ ¼ç­›é€‰ Top 30

# === ğŸ›‘ 1. æ”¿æ²»å™ªéŸ³è¯ (å‡ºç°å³é™æƒï¼Œé™¤éæœ‰è±å…) ===
POLITICAL_NOISE = [
    "woke", "maga", "democrat", "republican", "leftist", "right wing", "liberal", "conservative",
    "fascist", "communist", "socialist", "pronouns", "dei", "border crisis", "illegal",
    "trump", "biden", "harris", "vance", "pelosi", "schumer", "election", "ballot",
    "scandal", "epstein", "pedophile", "traitor", "shame", "disgrace", "culture war"
]

# === ğŸ”° 2. å®è§‚è±å…è¯ (ä¿æŠ¤æ­£ç»äº‹) ===
# å³ä½¿æœ‰ Trumpï¼Œå¦‚æœæœ‰è¿™äº›è¯ï¼Œä¹Ÿè§†ä¸ºé«˜ä»·å€¼æƒ…æŠ¥
MACRO_IMMUNITY = [
    "fed", "federal reserve", "powell", "fomc", "rate", "interest", "cut", "hike",
    "tariff", "trade war", "sanction", "export", "import", "duty",
    "china", "taiwan", "russia", "ukraine", "israel", "iran", "war", "military",
    "stimulus", "debt", "deficit", "budget", "tax", "treasury", "bond", "yield",
    "bitcoin", "btc", "crypto", "ban", "regulation", "sec", "gensler", "etf",
    "executive order", "veto", "sign", "bill", "act", "law", "legislation",
    "nominate", "nominee", "appoint", "confirm", "supreme court"
]

# === ğŸ§  3. è¯é¢˜è¯†åˆ«åº“ (ç”¨äºæ‰“æ ‡ç­¾ + æ ¸å¿ƒåŠ åˆ†) ===
TOPIC_KEYWORDS = {
    "Crypto": [
        "bitcoin", "btc", "eth", "solana", "defi", "nft", "stablecoin", "etf", "blackrock",
        "airdrop", "staking", "binance", "coinbase", "satoshi", "vitalik", "wallet"
    ],
    "AI/Tech": [
        "ai", "llm", "transformer", "inference", "training", "gpt", "claude", "gemini",
        "nvidia", "gpu", "h100", "cuda", "tsmc", "asml", "chip", "semiconductor",
        "spacex", "tesla", "fsd", "optimus", "python", "code", "github", "arxiv"
    ],
    "Science": [
        "nature", "science", "arxiv", "paper", "nasa", "jwst", "supernova", "quantum",
        "superconductor", "fusion", "crispr", "cancer", "alzheimer", "longevity"
    ],
    "Macro": [
        "sp500", "nasdaq", "bond", "yield", "gold", "oil", "revenue", "earnings",
        "fed", "rate", "cpi", "inflation", "gdp", "recession", "unemployment", "debt"
    ],
    "Geo": [
        "ukraine", "russia", "israel", "iran", "china", "taiwan", "war", "military", "nuclear"
    ]
}

# === ğŸ›¡ï¸ 4. VIP ç™½åå• (ä¿é€æœºåˆ¶) ===
VIP_AUTHORS = [
    "Karpathy", "Yann LeCun", "Vitalik", "Paul Graham", "Naval", 
    "Eric Topol", "Huberman", "Lex Fridman", "Sam Altman", "Kobeissi Letter",
    "Michael Saylor", "Balaji"
]

def fmt_k(num):
    if not num: return "0"
    try: n = float(num)
    except: return "0"
    if n >= 1_000_000: return f"{n/1_000_000:.1f}M"
    if n >= 1_000: return f"{n/1_000:.1f}K"
    return str(int(n))

def to_iso_bj(date_str):
    try:
        utc_dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S +0000 %Y')
        return (utc_dt + timedelta(hours=8)).isoformat()
    except: return datetime.now().isoformat()

def process(raw_data, path):
    items = raw_data if isinstance(raw_data, list) else [raw_data]
    refined_results = []
    for i in items:
        user = i.get('user', {})
        metrics = i.get('metrics', {})
        row = {
            "bj_time": to_iso_bj(i.get('createdAt')),
            "user_name": user.get('name'),
            "screen_name": user.get('screenName'),
            "followers_count": user.get('followersCount'),
            "full_text": i.get('fullText'),
            "url": i.get('tweetUrl'), 
            "tags": i.get('tags', []),
            "likes": metrics.get('likes', 0),
            "retweets": metrics.get('retweets', 0),
            "bookmarks": metrics.get('bookmarks', 0),
            "raw_json": i 
        }
        refined_results.append(row)
    return refined_results

# ğŸ”¥ æ ¸å¿ƒï¼šä¸Šå¸æƒé‡ç®—æ³• ğŸ”¥
def calculate_score_and_tag(item):
    text = (item.get('full_text') or "").lower()
    user = (item.get('user_name') or "")
    
    # 1. åŸºç¡€çƒ­åº¦ (ä¹¦ç­¾æƒé‡æœ€é«˜ï¼Œä»£è¡¨æ·±åº¦ä»·å€¼)
    metrics = item.get('raw_json', {}).get('metrics', {})
    likes = metrics.get('likes', 0)
    retweets = metrics.get('retweets', 0)
    bookmarks = metrics.get('bookmarks', 0)
    base_score = (retweets * 5) + (bookmarks * 10) + likes
    
    # 2. è¯é¢˜è¯†åˆ« & åŠ æƒ
    detected_topic = "General"
    is_hardcore = False
    
    for topic, keywords in TOPIC_KEYWORDS.items():
        for k in keywords:
            if k in text:
                detected_topic = topic
                is_hardcore = True
                break
        if is_hardcore: break
    
    # ç¡¬æ ¸è¯é¢˜åŠ åˆ† (Tech, Crypto, Science, Macro)
    if is_hardcore:
        base_score += 2000 # åªè¦æ²¾è¾¹ç¡¬æ ¸ï¼Œèµ·æ­¥åˆ†æ‹‰é«˜
        base_score *= 1.5  # å€ç‡åŠ æˆ
        
    # 3. æ”¿æ²»æ’æ¯’ (é€»è¾‘ï¼šæœ‰å™ªéŸ³ä¸”æ— è±å… -> é™æƒ)
    has_noise = False
    for noise in POLITICAL_NOISE:
        if noise in text:
            has_noise = True
            break
            
    if has_noise:
        is_immune = False
        for safe in MACRO_IMMUNITY:
            if safe in text:
                is_immune = True
                break
        if not is_immune:
            base_score *= 0.1 # é™æƒæ‰“å‡»
            detected_topic = "Politics" # å¼ºåˆ¶æ ‡è®°ä¸ºæ”¿æ²»
            
    # 4. VIP åŠ æˆ
    for vip in VIP_AUTHORS:
        if vip.lower() in user.lower():
            base_score += 5000
            break
            
    return base_score, detected_topic

def get_hot_items(supabase, table_name):
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_tweets = res.data if res.data else []
    except Exception as e: return {}

    if not all_tweets: return {}

    # 1. URL å»é‡
    unique_map = {}
    for t in all_tweets:
        key = t.get('url') or (t.get('user_name'), t.get('full_text'))
        if key not in unique_map:
            unique_map[key] = t
    tweets = list(unique_map.values())

    # 2. ç®—åˆ† & æ‰“æ ‡
    scored_tweets = []
    for t in tweets:
        score, topic = calculate_score_and_tag(t)
        t['_score'] = score
        t['_topic'] = topic
        scored_tweets.append(t)
        
    # 3. å…¨å±€æ’åº
    scored_tweets.sort(key=lambda x: x['_score'], reverse=True)
    
    # 4. ğŸ›¡ï¸ ç†”æ–­æœºåˆ¶ (Diversity Breaker) ğŸ›¡ï¸
    # åº”å¯¹å¤§æ•°æ®é‡çš„å…³é”®ï¼šé˜²æ­¢åŒä¸€ä¸ªäººéœ¸æ¦œ
    final_list = []
    author_counts = {}
    
    for t in scored_tweets:
        if len(final_list) >= TARGET_TOTAL_QUOTA:
            break
            
        author = t['user_name']
        # é™åˆ¶æ¯ä¸ªåšä¸»æœ€å¤š 3 æ¡
        if author_counts.get(author, 0) >= 3:
            continue 
            
        final_list.append(t)
        author_counts[author] = author_counts.get(author, 0) + 1
        
    # 5. ç”Ÿæˆå•å¼ å¤§è¡¨
    header = "| ä¿¡å· | ğŸ·ï¸ æ ‡ç­¾ | çƒ­åº¦ | åšä¸» | æ‘˜è¦ | ğŸ”— |\n| :--- | :--- | :--- | :--- | :--- | :--- |"
    rows = []
    
    for t in final_list:
        score_display = fmt_k(t['_score'])
        topic_display = f"`{t['_topic']}`" # ä»£ç å—æ ·å¼
        
        heat = f"â¤ï¸ {fmt_k(t.get('likes',0))}<br>ğŸ” {fmt_k(t.get('retweets',0))}" 
        user = t['user_name']
        text = t['full_text'].replace('\n', ' ')[:70] + "..."
        url = t['url']
        
        rows.append(f"| **{score_display}** | {topic_display} | {heat} | {user} | {text} | [ğŸ”—]({url}) |")

    return {"ğŸ† å…¨åŸŸç²¾é€‰ (Top 30)": {"header": header, "rows": rows}}
