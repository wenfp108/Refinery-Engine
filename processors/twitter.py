import json
import math
from datetime import datetime, timedelta

# === âš™ï¸ é…ç½®åŒº (å·²æ›´æ–°) ===

TABLE_NAME = "twitter_logs"
TARGET_TOTAL_QUOTA = 30  # ğŸŒŸ æœ€ç»ˆåªé€‰å‡ºå…¨ç½‘æœ€å¥½çš„ 30 æ¡

# === ğŸ›‘ 1. æ”¿æ²»/åƒåœ¾å™ªéŸ³è¯ (å·²é’ˆå¯¹æ–°æ¿å—ä¼˜åŒ–) ===
# æ—¢ç„¶ "Politics" ç°åœ¨æ˜¯æ­£ç»æ¿å—ï¼Œæˆ‘ä»¬åªæ€æ— æ„ä¹‰çš„æƒ…ç»ªå®£æ³„è¯
NOISE_KEYWORDS = [
    "woke", "libtard", "magatard", "shame", "disgrace", "traitor", 
    "pedophile", "epstein", "pronouns", "culture war", "scandal",
    "destroy", "lies", "liar", "clown", "hypocrite", "idiot"
]

# === ğŸ”° 2. å®è§‚è±å…è¯ (ä¿æŠ¤é•¿æ–‡ä¸è¢«è¯¯æ€) ===
MACRO_IMMUNITY = [
    "fed", "federal reserve", "powell", "fomc", "rate", "interest", "cut", "hike",
    "tariff", "trade war", "sanction", "export", "import", "duty",
    "china", "taiwan", "russia", "ukraine", "israel", "iran", "war", "military",
    "stimulus", "debt", "deficit", "budget", "tax", "treasury", "bond", "yield",
    "bitcoin", "btc", "crypto", "ban", "regulation", "sec", "etf",
    "executive order", "veto", "sign", "bill", "act", "law", "legislation",
    "nominate", "nominee", "appoint", "confirm", "supreme court", "ruling"
]

# === ğŸ§  3. ç²¾å‡†è¯é¢˜è¯åº“ (7å¤§æ¿å— - æƒé‡ç«ä»·æ¨¡å¼) ===
# åŒ…å«ï¼šTech, Politics, Finance, Economy, Geo, Science, Crypto
TOPIC_RULES = {
    "Tech": [ # ç§‘æŠ€ï¼šAI, èŠ¯ç‰‡, ç¼–ç¨‹, ç¡¬ç§‘æŠ€
        "llm", "genai", "gpt-5", "gpt-4", "claude", "gemini", "llama", "deepseek", "anthropic", "openai",
        "nvidia", "nvda", "h100", "blackwell", "cuda", "gpu", "semiconductor", "tsmc", "asml", "wafer",
        "spacex", "starship", "falcon", "tesla", "tsla", "fsd", "robot", "optimus", "figure ai",
        "python", "rust", "github", "huggingface", "open source", "coding"
    ],
    "Politics": [ # æ”¿æ²»ï¼šé€‰ä¸¾, ç«‹æ³•, æœºæ„ (æ­£ç»è®¨è®º)
        "white house", "biden", "trump", "harris", "vance", "congress", "senate", "house of rep",
        "supreme court", "scotus", "legislation", "bill", "veto", "executive order", "amendment",
        "election", "poll", "voter", "ballot", "campaign", "republican", "democrat", "gop", "dnc"
    ],
    "Finance": [ # é‡‘èï¼šäºŒçº§å¸‚åœº, æŠ•è¡Œ, è´¢æŠ¥ (Micro)
        "sp500", "nasdaq", "spx", "ndx", "dow jones", "russell 2000", "vix",
        "stock", "equity", "earnings", "revenue", "margin", "guidance", "buyback", "dividend",
        "goldman", "jpmorgan", "morgan stanley", "bloomberg", "blackrock", "citadel",
        "ipo", "merger", "acquisition", "short seller", "long position", "call option", "put option"
    ],
    "Economy": [ # ç»æµï¼šå®è§‚, å¤®è¡Œ, å‘¨æœŸ (Macro)
        "fomc", "federal reserve", "jerome powell", "fed funds", "interest rate", "hike", "cut",
        "cpi", "ppi", "pce", "inflation", "deflation", "stagflation", "recession", "soft landing",
        "gdp", "unemployment", "jobless", "non-farm", "payroll", "labor market",
        "treasury", "bond yield", "10y", "2y", "curve inversion", "debt ceiling", "deficit"
    ],
    "Geo": [ # åœ°ç¼˜ï¼šæˆ˜äº‰, å¤–äº¤, åˆ¶è£
        "ukraine", "russia", "putin", "zelensky", "kursk", "kyiv",
        "israel", "gaza", "hamas", "iran", "tehran", "red sea", "houthi", "hezbollah",
        "china", "xi jinping", "taiwan", "south china sea", "pla", "ccp",
        "nato", "pentagon", "nuclear", "weapon", "sanction", "trade war", "tariff"
    ],
    "Science": [ # ç§‘å­¦ï¼šå­¦æœ¯, èƒ½æº, ç”Ÿç‰©, èˆªå¤©
        "nature journal", "science magazine", "arxiv", "peer review", "preprint",
        "nasa", "esa", "jwst", "supernova", "exoplanet", "quantum", "fusion energy", "lk-99",
        "crispr", "mrna", "cancer", "alzheimer", "longevity", "biology", "physics", "chemistry"
    ],
    "Crypto": [ # åŠ å¯†ï¼šWeb3, å¸, é“¾
        "bitcoin", "btc", "ethereum", "eth", "solana", "defi", "stablecoin", "usdc", "usdt",
        "etf flow", "blackrock", "coinbase", "binance", "satoshi", "vitalik", "memecoin",
        "wallet", "private key", "smart contract", "layer2", "zk-rollup", "airdrop"
    ]
}

# === ğŸ›¡ï¸ 4. VIP ç™½åå• (åŸºç¡€åˆ†åŠ æˆ) ===
# åŸºäºä½ æä¾›çš„åˆ—è¡¨æ•´åˆï¼Œæ¶µç›–æ‰€æœ‰æ¿å—é¢†è¢–
VIP_AUTHORS = [
    # Tech / AI
    "Karpathy", "Yann LeCun", "Paul Graham", "Sam Altman", "FranÃ§ois Chollet", 
    "Rowan Cheung", "Naval", "Palmer Luckey", "Anduril", "Elon Musk",
    
    # Finance / Macro / Economy
    "Nick Timiraos", "Ray Dalio", "Mohamed A. El-Erian", "Kobeissi Letter", 
    "Walter Bloomberg", "Zerohedge", "Lyn Alden", "MacroAlf", "Goldman Sachs",
    "Peter Schiff", "Michael Saylor", "Nassim Nicholas Taleb", "CME Group",
    "Fitch Ratings", "IMF", "Unusual Whales", "The Economist", "WSJ Central Banks",
    
    # Geo / Politics / Science
    "Ian Bremmer", "Eric Topol", "Vitalik", "SentDefender", "VisegrÃ¡d 24",
    "Spectator Index", "Disclose.tv", "Defense News", "Council on Foreign Relations"
]

# === âš™ï¸ æ ¸å¿ƒé€»è¾‘å‡½æ•° (å®Œå…¨ä¿æŒåŸæ ·) ===

def fmt_k(num):
    if not num: return "0"
    try: n = float(num)
    except: return "0"
    if n >= 1_000_000: return f"{n/1_000_000:.1f}M"
    if n >= 1_000: return f"{n/1_000:.1f}K"
    return str(int(n))

def to_iso_bj(date_str):
    try:
        utc_dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S +0000 %Y')
        return (utc_dt + timedelta(hours=8)).isoformat()
    except: return datetime.now().isoformat()

def process(raw_data, path):
    items = raw_data if isinstance(raw_data, list) else [raw_data]
    refined_results = []
    for i in items:
        # ğŸ—‘ï¸ åƒåœ¾è¿‡æ»¤ï¼šæ€æ‰ "Yes..." è¿™ç§æ°´è´´
        text = i.get('fullText', '')
        # å¦‚æœæ­£æ–‡å¤ªçŸ­(<10å­—)ä¸”ä¸åŒ…å«é“¾æ¥ï¼Œç›´æ¥ä¸¢å¼ƒ
        if len(text) < 10 and 'http' not in text:
            continue

        user = i.get('user', {})
        metrics = i.get('metrics', {})
        row = {
            "bj_time": to_iso_bj(i.get('createdAt')),
            "user_name": user.get('name'),
            "screen_name": user.get('screenName'),
            "followers_count": user.get('followersCount'),
            "full_text": text,
            "url": i.get('tweetUrl'), 
            "tags": i.get('tags', []),
            "likes": metrics.get('likes', 0),
            "retweets": metrics.get('retweets', 0),
            "bookmarks": metrics.get('bookmarks', 0),
            "raw_json": i 
        }
        refined_results.append(row)
    return refined_results

# ğŸ”¥ æ ¸å¿ƒï¼šä¸Šå¸æƒé‡ç®—æ³• 4.0 (Final Logic) ğŸ”¥
def calculate_score_and_tag(item):
    text = (item.get('full_text') or "").lower()
    user = (item.get('user_name') or "")
    
    # 1. åŸºç¡€çƒ­åº¦ (ä¹¦ç­¾ x10, è½¬æ¨ x5, ç‚¹èµ x1)
    metrics = item.get('raw_json', {}).get('metrics', {})
    base_score = (metrics.get('retweets', 0) * 5) + \
                 (metrics.get('bookmarks', 0) * 10) + \
                 metrics.get('likes', 0)
    
    # 2. è¯é¢˜ç«ä»· (Strict Tagging)
    detected_topic = "General"
    max_keyword_len = 0 # åŒ¹é…åˆ°çš„å…³é”®è¯è¶Šé•¿ï¼Œç½®ä¿¡åº¦è¶Šé«˜
    
    for topic, keywords in TOPIC_RULES.items():
        for k in keywords:
            if k in text:
                if len(k) > max_keyword_len:
                    detected_topic = topic
                    max_keyword_len = len(k)
    
    # 3. è¯­ä¹‰åŠ æƒ vs é™æƒ
    if detected_topic != "General":
        # ğŸ’ å‘½ä¸­ç¡¬æ ¸æ¿å—ï¼šå¤§å¹…åŠ åˆ†
        base_score += 2000
        base_score *= 1.5
    else:
        # ğŸ“‰ General æƒ©ç½š
        base_score *= 0.5 

    # 4. æ”¿æ²»æ’æ¯’ (Nuclear Detox)
    has_noise = False
    for noise in NOISE_KEYWORDS:
        if noise in text:
            has_noise = True
            break
            
    if has_noise:
        is_immune = False
        for safe in MACRO_IMMUNITY:
            if safe in text:
                is_immune = True
                break
        
        if not is_immune:
            base_score *= 0.1 # ğŸ’£ æ— è±å…çš„å™ªéŸ³
            detected_topic = "Politics" # å¼ºåˆ¶å½’ç±»ä¸º(å)æ”¿æ²»
            
    # 5. VIP åŠ æˆ
    for vip in VIP_AUTHORS:
        if vip.lower() in user.lower():
            base_score += 5000
            break
            
    return base_score, detected_topic

def get_hot_items(supabase, table_name):
    yesterday = (datetime.now() - timedelta(hours=24)).isoformat()
    try:
        res = supabase.table(table_name).select("*").gt("bj_time", yesterday).execute()
        all_tweets = res.data if res.data else []
    except Exception as e: return {}

    if not all_tweets: return {}

    # 1. URL å»é‡
    unique_map = {}
    for t in all_tweets:
        key = t.get('url') or (t.get('user_name'), t.get('full_text'))
        if key not in unique_map:
            unique_map[key] = t
    tweets = list(unique_map.values())

    # 2. ç®—åˆ† & æ‰“æ ‡
    scored_tweets = []
    for t in tweets:
        score, topic = calculate_score_and_tag(t)
        t['_score'] = score
        t['_topic'] = topic
        scored_tweets.append(t)
        
    # 3. å…¨å±€æ’åº
    scored_tweets.sort(key=lambda x: x['_score'], reverse=True)
    
    # 4. ğŸ›¡ï¸ å¤šæ ·æ€§ç†”æ–­ (Diversity Breaker)
    final_list = []
    author_counts = {}
    
    for t in scored_tweets:
        if len(final_list) >= TARGET_TOTAL_QUOTA:
            break
            
        author = t['user_name']
        if author_counts.get(author, 0) >= 3:
            continue
            
        final_list.append(t)
        author_counts[author] = author_counts.get(author, 0) + 1
        
    # 5. ç”Ÿæˆæˆ˜æŠ¥
    header = "| ä¿¡å· | ğŸ·ï¸ æ ‡ç­¾ | çƒ­åº¦ | åšä¸» | æ‘˜è¦ | ğŸ”— |\n| :--- | :--- | :--- | :--- | :--- | :--- |"
    rows = []
    
    for t in final_list:
        score_display = fmt_k(t['_score'])
        
        topic_raw = t['_topic']
        if topic_raw in ["General"]: 
            topic_str = topic_raw
        else: 
            topic_str = f"**{topic_raw}**"
        
        heat = f"â¤ï¸ {fmt_k(t.get('likes',0))}<br>ğŸ” {fmt_k(t.get('retweets',0))}" 
        
        user = t['user_name']
        text = t['full_text'].replace('\n', ' ')[:70] + "..."
        url = t['url']
        
        rows.append(f"| **{score_display}** | {topic_str} | {heat} | {user} | {text} | [ğŸ”—]({url}) |")

    return {"ğŸ† å…¨åŸŸç²¾é€‰ (Top 30)": {"header": header, "rows": rows}}
