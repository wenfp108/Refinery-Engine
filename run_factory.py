import os
import pandas as pd
from datetime import datetime, timedelta, timezone
from supabase import create_client
from factory import UniversalFactory  # å¯¼å…¥ä½ çš„é€šç”¨å·¥å‚ç±»

# === âš™ï¸ é…ç½®åŒº ===
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# ä½ çš„ä¸­å¤®é“¶è¡Œåœ¨ GitHub Action é‡Œçš„ç›¸å¯¹è·¯å¾„ (æ ¹æ® workflow é…ç½®)
VAULT_PATH = "../vault"

# ä½ æ‰€æœ‰çš„æƒ…æŠ¥æºè¡¨å (éœ€è¦ä¸ processors é‡Œçš„ TABLE_NAME ä¸€è‡´)
TARGET_TABLES = [
    "polymarket_logs",
    "twitter_logs",
    "reddit_logs",
    "github_logs",
    "papers_logs"
]

def fetch_fresh_data(table_name, minutes=70):
    """
    ä»æŒ‡å®šè¡¨æå–æœ€è¿‘ N åˆ†é’Ÿçš„æ•°æ®
    (70åˆ†é’Ÿæ˜¯ä¸ºäº†ç¨å¾®è¦†ç›–æ•´ç‚¹ï¼Œé˜²æ­¢è¾¹ç¼˜æ•°æ®é—æ¼)
    """
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        
        # è®¡ç®—æ—¶é—´é˜ˆå€¼ (UTC æ—¶é—´ï¼Œå› ä¸º Supabase å†…éƒ¨é€šå¸¸å­˜ UTC æˆ–å¸¦æ—¶åŒºçš„ ISO)
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ä½ çš„ bj_time æ˜¯ ISO æ ¼å¼å­—ç¬¦ä¸²
        # ä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬ç”¨å½“å‰æ—¶é—´å‡å» 70 åˆ†é’Ÿçš„ ISO å­—ç¬¦ä¸²è¿›è¡Œå­—ç¬¦ä¸²æ¯”è¾ƒ
        # (åªè¦æ ¼å¼æ˜¯æ ‡å‡†çš„ ISO 8601ï¼Œå­—ç¬¦ä¸²æ¯”è¾ƒå°±æ˜¯æœ‰æ•ˆçš„)
        cutoff_time = (datetime.now(timezone.utc) - timedelta(minutes=minutes)).isoformat()
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä½ çš„ bj_time æ˜¯ +08:00ï¼Œè¿™é‡Œæœ€å¥½ä¹Ÿè½¬æ¢ä¸€ä¸‹
        # ç®€å•èµ·è§ï¼Œè¿™é‡Œç›´æ¥åˆ©ç”¨ Supabase çš„è¿‡æ»¤å™¨
        
        print(f"ğŸ£ [{table_name}] æ­£åœ¨æ‰«ææ–°æ•°æ®...")
        
        # é™åˆ¶å•æ¬¡æœ€å¤§è·å– 1000 æ¡ï¼Œé˜²æ­¢å†…å­˜çˆ†
        res = supabase.table(table_name)\
            .select("*")\
            .gt("bj_time", cutoff_time)\
            .limit(1000)\
            .execute()
            
        data = res.data
        if data:
            print(f"   âœ… æ•è· {len(data)} æ¡ä¿¡å·")
            return data
        else:
            print(f"   ğŸ’¤ æ— æ–°å¢ä¿¡å·")
            return []
            
    except Exception as e:
        print(f"   âš ï¸ [{table_name}] è¯»å–å¤±è´¥: {e}")
        return []

def main():
    print(f"ğŸš€ [Cognitive Factory] å¯åŠ¨æ—¶é—´: {datetime.now().isoformat()}")
    
    all_signals = []
    
    # 1. éå†æ‰€æœ‰æºï¼Œæ”¶é›†æ–°é²œåŸæ–™
    for table in TARGET_TABLES:
        rows = fetch_fresh_data(table)
        if rows:
            all_signals.extend(rows)
            
    if not all_signals:
        print("ğŸ“­ æœ¬è½®å·¡æ£€æœªå‘ç°ä»»ä½•æ–°æ•°æ®ï¼Œå·¥å‚ä¼‘çœ ã€‚")
        return

    print(f"ğŸ“¦ åŸæ–™å‡†å¤‡å®Œæ¯•ï¼Œå…±è®¡ {len(all_signals)} æ¡æ··åˆä¿¡å·ã€‚")

    # 2. è½¬æ¢ä¸º DataFrame å¹¶ä¿å­˜ä¸ºä¸´æ—¶ Parquet
    # (Factory åªåƒ Parquetï¼Œè¿™æ ·å¯ä»¥ä¿æŒæ¥å£ç»Ÿä¸€)
    df = pd.DataFrame(all_signals)
    temp_file = "temp_run_batch.parquet"
    
    # å…¼å®¹æ€§ï¼šç¡®ä¿ numeric å­—æ®µæ˜¯æ•°å­—ç±»å‹ï¼Œé˜²æ­¢æŠ¥é”™
    for col in ['volume', 'liquidity', 'vol24h', 'day_change', 'stars', 'citations']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
    df.to_parquet(temp_file)

    # 3. å”¤é†’å¤§å¸ˆï¼Œå¼€å·¥
    # masters_path="masters" å¯¹åº” workflow é‡Œå¤åˆ¶è¿‡æ¥çš„æ’ä»¶ç›®å½•
    try:
        factory = UniversalFactory(masters_path="masters")
        
        print("ğŸ­ æµæ°´çº¿å…¨é€Ÿè¿è½¬ä¸­...")
        factory.process_and_ship(
            input_raw=temp_file, 
            vault_path=VAULT_PATH
        )
        
    except Exception as e:
        print(f"âŒ å·¥å‚è¿è¡Œä¸¥é‡é”™è¯¯: {e}")
        
    finally:
        # 4. æ¸…ç†ç°åœº (ç„šçƒ§ä¸´æ—¶æ–‡ä»¶)
        if os.path.exists(temp_file):
            os.remove(temp_file)
            print("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†ã€‚")

if __name__ == "__main__":
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ [é”™è¯¯] ç¯å¢ƒå˜é‡ç¼ºå¤± (SUPABASE_URL/KEY)")
    else:
        main()
